{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vision (Understanding Images)\n",
    "## Introduction\n",
    "\n",
    "GPT-4 with Vision, sometimes referred to as GPT-4V or gpt-4-vision-preview in the API, allows the model to take in images and answer questions about them.\n",
    "\n",
    "GPT-4 with vision is currently available to all developers who have access to GPT-4 via the gpt-4-vision-preview model and the Chat Completions API which has been updated to support image inputs. Note that the Assistants API does not currently support image inputs.\n",
    "\n",
    "> **Note** Currently, GPT-4 Turbo with vision does not support the message.name parameter, functions/tools, response_format parameter, and we currently set a low max_tokens default which you can override.\n",
    "\n",
    "Images are made available to the model in two main ways: by passing a link to the image or by passing the base64 encoded image directly in the request. Images can be passed in the user, system and assistant messages. Currently we don't support images in the first system message but this may change in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='The image depicts a serene natural scene with a wooden boardwalk extending through a lush green field. The boardwalk creates a straight path and invites a walk through the tall grasses surrounding it. The field is abundant with greenery, possibly indicating spring or summer season. The sky is clear with a few scattered, wispy clouds, with the sunlight casting a warm glow on the landscape, enhancing the vivid colors of the flora. This could be a natural reserve, park, or a wetland area where boardwalks are commonly built to facilitate access without disturbing the natural environment.', role='assistant', function_call=None, tool_calls=None))\n"
     ]
    }
   ],
   "source": [
    "# Sending image as a URL\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": [\n",
    "        {\"type\": \"text\", \"text\": \"What’s in this image?\"},\n",
    "        {\n",
    "          \"type\": \"image_url\",\n",
    "          \"image_url\": {\n",
    "            \"url\": \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg\",\n",
    "          },\n",
    "        },\n",
    "      ],\n",
    "    }\n",
    "  ],\n",
    "  max_tokens=300,\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image shows a beautiful snowy landscape with unique geological formations. These formations, characterized by their rugged, rocky outcrops and peaks, suggest that this might be a region with a history of volcanic activity, often resulting in such stark and impressive natural features. The snow adds a contrasting layer to the otherwise dry and eroded rocks, highlighting the natural beauty of the place. There are no visible human figures in this photograph, keeping the focus on the natural environment. The clear blue sky suggests it is a sunny day, and the distant mountain in the background adds depth to the scene, underscoring the wild and expansive topography of the area. This kind of terrain is often found in regions known for their historic and geological significance.\n"
     ]
    }
   ],
   "source": [
    "# Sending image as a base64 encoded string\n",
    "from openai import OpenAI\n",
    "import base64\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "image_path = \"data/cappadocia.jpeg\"\n",
    "\n",
    "# Function to encode the image\n",
    "with open(image_path, \"rb\") as image_file:\n",
    "    base64_image = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": [\n",
    "        {\"type\": \"text\", \"text\": \"What’s in this image?\"},\n",
    "        {\n",
    "          \"type\": \"image_url\",\n",
    "          \"image_url\": {\n",
    "            \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "          },\n",
    "        },\n",
    "      ],\n",
    "    }\n",
    "  ],\n",
    "  max_tokens=300,\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The images you've provided seem to be identical. Both showcase a wooden boardwalk extending through a lush, green wetland or grassland. The sky is blue with some wispy clouds, and there is a variety of green vegetation on either side of the path. There doesn't appear to be any discernible difference between the two images; they seem to be two copies of the same photo.\n"
     ]
    }
   ],
   "source": [
    "# Multiple image inputs\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": [\n",
    "        {\n",
    "          \"type\": \"text\",\n",
    "          \"text\": \"What are in these images? Is there any difference between them?\",\n",
    "        },\n",
    "        {\n",
    "          \"type\": \"image_url\",\n",
    "          \"image_url\": {\n",
    "            \"url\": \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg\",\n",
    "          },\n",
    "        },\n",
    "        {\n",
    "          \"type\": \"image_url\",\n",
    "          \"image_url\": {\n",
    "            \"url\": \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg\",\n",
    "          },\n",
    "        },\n",
    "      ],\n",
    "    }\n",
    "  ],\n",
    "  max_tokens=300,\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Low or high fidelity\n",
    "By controlling the detail parameter, which has three options, `low`, `high`, or `auto`, you have control over how the model processes the image and generates its textual understanding. By default, the model will use the `auto` setting which will look at the image input size and decide if it should use the `low` or `high` setting.\n",
    "\n",
    "* `low` will disable the “high res” model. The model will receive a low-res 512px x 512px version of the image, and represent the image with a budget of 85 tokens. This allows the API to return faster responses and consume fewer input tokens for use cases that do not require high detail.\n",
    "* `high` will enable “high res” mode, which first allows the model to see the low res image and then creates detailed crops of input images as 512px squares based on the input image size. Each of the detailed crops uses twice the token budget (85 * 2 = 170 tokens).\n",
    "\n",
    "Image inputs are metered and charged in tokens, just as text inputs are. The token cost of a given image is determined by two factors: its size, and the detail option on each image_url block. All images with `detail: low` cost 85 tokens each. `detail: high` images are first scaled to fit within a 2048 x 2048 square, maintaining their aspect ratio. Then, they are scaled such that the shortest side of the image is 768px long. Finally, we count how many 512px squares the image consists of. Each of those squares costs 170 tokens. Another 85 tokens are always added to the final total.\n",
    "\n",
    "Here are some examples demonstrating the above.\n",
    "\n",
    "* A 1024 x 1024 square image in detail: high mode costs 765 tokens\n",
    "    * 1024 is less than 2048, so there is no initial resize.\n",
    "    * The shortest side is 1024, so we scale the image down to 768 x 768.\n",
    "    * 4 512px square tiles are needed to represent the image, so the final token cost is 170 * 4 + 85 = 765.\n",
    "\n",
    "* A 2048 x 4096 image in detail: high mode costs 1105 tokens\n",
    "\n",
    "    * We scale down the image to 1024 x 2048 to fit within the 2048 square.\n",
    "    * The shortest side is 1024, so we further scale down to 768 x 1536.\n",
    "    * 6 512px tiles are needed, so the final token cost is 170 * 6 + 85 = 1105.\n",
    "\n",
    "* A 4096 x 8192 image in detail: low most costs 85 tokens\n",
    "    * Regardless of input size, low detail images are a fixed cost.\n",
    "\n",
    "\n",
    "In the following code, example the input image is 2560 * 1669. In high fidelity:\n",
    "\n",
    "* Since it is larger then 2048, it will be first resized to 2048 * 1335.\n",
    "* Then, the shortest side will be scaled down to 768, resulting 1178 * 768.\n",
    "* 6 512px tiles are needed, so the final token cost for the input image is 170 * 6 + 85 = 1105.\n",
    "\n",
    "In low fidelity: Regardless of input size, low detail images are a fixed cost of 85 tokens.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** High Fidelity ***\n",
      "The image shows a wooden boardwalk traversing through a lush green field with tall grass on either side. The sky is a beautiful blue with some scattered white clouds. It appears to be a sunny day, and the scene is tranquil, possibly a nature reserve or park where boardwalks are installed to allow people to enjoy the landscape without disturbing the natural environment. The image has a sense of depth, leading the observer's eye along the boardwalk towards the horizon.\n",
      "Prompt Tokens: 1118, Completion Tokens: 93, Total Tokens: 1211\n",
      "*** Low Fidelity ***\n",
      "The image depicts a serene natural landscape. It features a wooden boardwalk or path that meanders through a lush green meadow filled with tall grass or reeds. The path invites one to walk through and enjoy the surrounding nature. The sky overhead is a bright blue with scattered white clouds, suggesting a pleasant day with good weather. The scene conveys a sense of tranquility and the beauty of a natural, untouched environment.\n",
      "Prompt Tokens: 98, Completion Tokens: 85, Total Tokens: 183\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "# High fidelity\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": [\n",
    "        {\"type\": \"text\", \"text\": \"What’s in this image?\"},\n",
    "        {\n",
    "          \"type\": \"image_url\",\n",
    "          \"image_url\": {\n",
    "            \"url\": \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg\",\n",
    "            \"detail\": \"high\"\n",
    "          },\n",
    "        },\n",
    "      ],\n",
    "    }\n",
    "  ],\n",
    "  max_tokens=300,\n",
    ")\n",
    "print(\"*** High Fidelity ***\")\n",
    "print(response.choices[0].message.content)\n",
    "print(f\"Prompt Tokens: {response.usage.prompt_tokens}, Completion Tokens: {response.usage.completion_tokens}, Total Tokens: {response.usage.total_tokens}\")\n",
    "\n",
    "# Low fidelity\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": [\n",
    "        {\"type\": \"text\", \"text\": \"What’s in this image?\"},\n",
    "        {\n",
    "          \"type\": \"image_url\",\n",
    "          \"image_url\": {\n",
    "            \"url\": \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg\",\n",
    "            \"detail\": \"low\"\n",
    "          },\n",
    "        },\n",
    "      ],\n",
    "    }\n",
    "  ],\n",
    "  max_tokens=300,\n",
    ")\n",
    "\n",
    "print(\"*** Low Fidelity ***\")\n",
    "print(response.choices[0].message.content)\n",
    "print(f\"Prompt Tokens: {response.usage.prompt_tokens}, Completion Tokens: {response.usage.completion_tokens}, Total Tokens: {response.usage.total_tokens}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Managing the images\n",
    "The Chat Completions API, unlike the Assistants API, is not stateful. That means you have to manage the messages (including images) you pass to the model yourself. If you want to pass the same image to the model multiple times, you will have to pass the image each time you make a request to the API.\n",
    "\n",
    "For long running conversations, we suggest passing images via URL's instead of base64. The latency of the model can also be improved by downsizing your images ahead of time to be less than the maximum size they are expected them to be. For low res mode, we expect a 512px x 512px image. For high res mode, the short side of the image should be less than 768px and the long side should be less than 2,000px.\n",
    "\n",
    "After an image has been processed by the model, it is deleted from OpenAI servers and not retained.\n",
    "\n",
    "OpenAI restricts image uploads to 20MB per image.\n",
    "\n",
    "They currently support PNG (.png), JPEG (.jpeg and .jpg), WEBP (.webp), and non-animated GIF (.gif)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
