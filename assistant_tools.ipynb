{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assistant Tools\n",
    "Give Assistants access to OpenAI-hosted tools like Code Interpreter and Knowledge Retrieval, or build your own tools using Function calling. Usage of OpenAI-hosted tools comes at an additional fee — visit [help center article](https://help.openai.com/en/articles/8550641-assistants-api) to learn more about how these tools are priced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Interpreter\n",
    "Code Interpreter allows the Assistants API to write and run Python code in a sandboxed execution environment. This tool can process files with diverse data and formatting, and generate files with data and images of graphs. Code Interpreter allows your Assistant to run code iteratively to solve challenging code and math problems. When your Assistant writes code that fails to run, it can iterate on this code by attempting to run different code until the code execution succeeds.\n",
    "\n",
    "Code Interpreter is charged at $0.03 per session. If your Assistant calls Code Interpreter simultaneously in two different threads (e.g., one thread per end-user), two Code Interpreter sessions are created. Each session is active by default for one hour, which means that you only pay for one session per if users interact with Code Interpreter in the same thread for up to one hour.\n",
    "\n",
    "To enable it, pass the `code_interpreter` in the `tools` parameter of the Assistant object to enable Code Interpreter. The model then decides when to invoke Code Interpreter in a Run based on the nature of the user request. This behavior can be promoted by prompting in the Assistant's instructions (e.g., “write code to solve this problem”)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Files with Code Interpreter\n",
    "Code Interpreter can parse data from files. This is useful when you want to provide a large volume of data to the Assistant or allow your users to upload their own files for analysis. Note that files uploaded for Code Interpreter are not indexed for retrieval. See the Knowledge Retrieval section below for more details on indexing files for retrieval.\n",
    "\n",
    "Files that are passed at the Assistant level are accessible by all Runs with this Assistant. Files can also be passed at individual Message level. These files are only accessible in the specific Thread."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlteam_utils import print_object\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "# Upload a file with an \"assistants\" purpose\n",
    "file = client.files.create(\n",
    "  file=open(\"data/AG_news_samples.csv\", \"rb\"),\n",
    "  purpose='assistants'\n",
    ")\n",
    "\n",
    "# Create an assistant with 'code_interpreter' enabled\n",
    "assistant = client.beta.assistants.create(\n",
    "  instructions=\"You are an assistant that does exploratory data analysis given a dataset as a CSV file. When asked a question about the data, write and run code to answer the question.\",\n",
    "  model=\"gpt-4-turbo-preview\",\n",
    "  tools=[{\"type\": \"code_interpreter\"}]\n",
    ")\n",
    "\n",
    "thread = client.beta.threads.create()\n",
    "\n",
    "message = client.beta.threads.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=\"How many news are labeled as 'Sports'?\",\n",
    "    file_ids=[file.id]\n",
    ")\n",
    "\n",
    "run = client.beta.threads.runs.create(\n",
    "  thread_id=thread.id,\n",
    "  assistant_id=assistant.id\n",
    ")\n",
    "\n",
    "# Wait for Run to be completed\n",
    "import time\n",
    "\n",
    "while True:\n",
    "    time.sleep(5)\n",
    "    run = client.beta.threads.runs.retrieve(\n",
    "      thread_id=thread.id,\n",
    "      run_id=run.id\n",
    "    )\n",
    "    if run.status in ['queued', 'in_progress', 'requires_action', 'cancelling']:\n",
    "        continue\n",
    "    if run.status in [\"completed\", \"expired\", \"failed\", \"cancelled\"]:\n",
    "        print(f\"Run is {run.status}\")\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the response\n",
    "messages = client.beta.threads.messages.list(\n",
    "  thread_id=thread.id\n",
    ")\n",
    "\n",
    "for message in reversed(messages.data):\n",
    "  print(f\"_______Role: {message.role}_______\\n\")\n",
    "  print(f\"{message.content[0].text.value}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading images and files generated by Code Interpreter\n",
    "Code Interpreter in the API also outputs files, such as generating image diagrams, CSVs, and PDFs. There are two types of files that are generated:\n",
    "\n",
    "1. Images\n",
    "2. Data files (e.g. a csv file with data generated by the Assistant)\n",
    "\n",
    "When Code Interpreter generates an image, you can look up and download this file in the file_id field of the Assistant Message response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new message to the previously created thread\n",
    "message = client.beta.threads.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=\"Can you give me a plot diagram with 'label' in the x axis, and count in the y axis?\"\n",
    ")\n",
    "\n",
    "run = client.beta.threads.runs.create(\n",
    "  thread_id=thread.id,\n",
    "  assistant_id=assistant.id\n",
    ")\n",
    "\n",
    "# Wait for Run to be completed\n",
    "import time\n",
    "\n",
    "while True:\n",
    "    time.sleep(5)\n",
    "    run = client.beta.threads.runs.retrieve(\n",
    "      thread_id=thread.id,\n",
    "      run_id=run.id\n",
    "    )\n",
    "    if run.status in ['queued', 'in_progress', 'requires_action', 'cancelling']:\n",
    "        continue\n",
    "    if run.status in [\"completed\", \"expired\", \"failed\", \"cancelled\"]:\n",
    "        print(f\"Run is {run.status}\")\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the response\n",
    "messages = client.beta.threads.messages.list(\n",
    "  thread_id=thread.id\n",
    ")\n",
    "\n",
    "# Print only the last message (which is assistant's response)\n",
    "message = messages.data[0]\n",
    "for i, content in enumerate(message.content):\n",
    "  if content.type == 'text':\n",
    "    print(f\"{content.text.value}\\n\")\n",
    "  elif content.type == 'image_file':\n",
    "    image_data = client.files.content(content.image_file.file_id)\n",
    "    image_data_bytes = image_data.read()\n",
    "    # Print the image\n",
    "    from IPython.display import display, Image\n",
    "    display(Image(data=image_data_bytes))\n",
    "    # You can also save to a file\n",
    "    with open(\"output/plot-image.png\", \"wb\") as file:\n",
    "      file.write(image_data_bytes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Message annotations\n",
    "Messages created by Assistants may contain annotations within the content array of the object. Annotations provide information around how you should annotate the text in the Message.\n",
    "\n",
    "There are two types of Annotations:\n",
    "\n",
    "1. `file_citation`: File citations are created by the `retrieval` tool and define references to a specific quote in a specific file that was uploaded and used by the Assistant to generate the response.\n",
    "2. `file_path`: File path annotations are created by the `code_interpreter` tool and contain references to the files generated by the tool.\n",
    "\n",
    "When annotations are present in the Message object, you'll see illegible model-generated substrings in the text that you should replace with the annotations. These strings may look something like 【13†source】 or sandbox:/mnt/data/file.csv. Here’s an example python code snippet that replaces these strings with information present in the annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new message to the previously created thread\n",
    "message = client.beta.threads.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=\"Can you create a new CSV file by removing all news in 'Business' category?\"\n",
    ")\n",
    "\n",
    "run = client.beta.threads.runs.create(\n",
    "  thread_id=thread.id,\n",
    "  assistant_id=assistant.id\n",
    ")\n",
    "\n",
    "# Wait for Run to be completed\n",
    "import time\n",
    "\n",
    "while True:\n",
    "    time.sleep(5)\n",
    "    run = client.beta.threads.runs.retrieve(\n",
    "      thread_id=thread.id,\n",
    "      run_id=run.id\n",
    "    )\n",
    "    if run.status in ['queued', 'in_progress', 'requires_action', 'cancelling']:\n",
    "        continue\n",
    "    if run.status in [\"completed\", \"expired\", \"failed\", \"cancelled\"]:\n",
    "        print(f\"Run is {run.status}\")\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our response will only have `file_path` annotations. But the following code also handles `file_citation` annotations.\n",
    "\n",
    "# Get the response\n",
    "messages = client.beta.threads.messages.list(\n",
    "  thread_id=thread.id\n",
    ")\n",
    "\n",
    "import os\n",
    "\n",
    "# Print only the last message (which is assistant's response)\n",
    "text = messages.data[0].content[0].text.value\n",
    "print(f\"_______Original text:_______\\n{text}\")\n",
    "\n",
    "annotations = messages.data[0].content[0].text.annotations\n",
    "citations = []\n",
    "for i, annotation in enumerate(annotations):\n",
    "    if (file_path := getattr(annotation, 'file_path', None)):\n",
    "        cited_file = client.files.retrieve(file_path.file_id)\n",
    "        cited_file_content = client.files.content(file_path.file_id)\n",
    "        file_name = \"output/\" + os.path.basename(cited_file.filename)\n",
    "        with open(file_name, \"wb\") as file:\n",
    "          file.write(cited_file_content.read())\n",
    "        text = text.replace(annotation.text, file_name)\n",
    "    elif (file_citation := getattr(annotation, 'file_citation', None)):\n",
    "        text = text.replace(annotation.text, f'[{i}]')\n",
    "        cited_file = client.files.retrieve(file_citation.file_id)\n",
    "        citations.append(f'[{i}] {file_citation.quote} from {cited_file.filename}')\n",
    "\n",
    "# Add footnotes to the end of the message before displaying to user\n",
    "if len(citations) > 0: \n",
    "  text += '\\n' + '\\n'.join(citations)\n",
    "print(f\"_______Processed text:_______\\n{text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input/Output Logs of Code Interpreter\n",
    "\n",
    "By listing the steps of a Run that called Code Interpreter, you can inspect the code input and outputs logs of Code Interpreter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_steps = client.beta.threads.runs.steps.list(\n",
    "    thread_id=thread.id,\n",
    "    run_id=run.id\n",
    ")\n",
    "\n",
    "for step in run_steps:\n",
    "    if (tool_calls := getattr(step.step_details, 'tool_calls', None)):\n",
    "        print_object(tool_calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup\n",
    "assistant_files = client.beta.assistants.files.list(assistant_id=assistant.id)\n",
    "for file in assistant_files:\n",
    "    client.files.delete(file_id=file.id)\n",
    "client.beta.assistants.delete(assistant_id=assistant.id)\n",
    "client.beta.threads.delete(thread_id=thread.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Knowledge Retrieval\n",
    "\n",
    "Retrieval augments the Assistant with knowledge from outside its model, such as proprietary product information or documents provided by your users. Once a file is uploaded and passed to the Assistant, OpenAI will automatically chunk your documents, index and store the embeddings, and implement vector search to retrieve relevant content to answer user queries.\n",
    "\n",
    "Pass the `retrieval` in the `tools` parameter of the Assistant to enable Retrieval. The model then decides when to retrieve content based on the user Messages. The Assistants API automatically chooses between two retrieval techniques:\n",
    "1. it either passes the file content in the prompt for short documents, or\n",
    "2. performs a vector search for longer documents\n",
    "\n",
    "### Using Files with Knowledge Retrieval\n",
    "Similar to Code Interpreter, files can be passed at the Assistant-level or individual Message-level. When a file is attached at the Message-level, it is only accessible within the specific Thread the Message is attached to. After having uploaded a file, you can pass the ID of this File when creating the Message. \n",
    "\n",
    "Note that you are not charged based on the size of the files you upload via the Files API but rather based on which files you attach to a specific Assistant or Message that get indexed.\n",
    "\n",
    "You can attach a maximum of 20 files per Assistant, and they can be at most 512 MB each. The size of all the files uploaded by your organization should not exceed 100 GB. You can request an increase in this storage limit using the [help center](https://help.openai.com/en/). In addition to the 512 MB file size limit, each file can only contain 2,000,000 tokens. Assistant or Message creation will fail if any attached files exceed the token limit.\n",
    "\n",
    "You can also use the `AssistantFile` object to create, delete, or view associations between Assistant and File objects. Note that deleting an AssistantFile doesn’t delete the original File object, it simply deletes the association between that File and the Assistant. To delete a File, use the File delete endpoint instead.\n",
    "\n",
    "### Supported files\n",
    "For text/ MIME types, the encoding must be one of `utf-8`, `utf-16`, or `ascii`.\n",
    "\n",
    "| FILE FORMAT | MIME TYPE                                                                 | CODE INTERPRETER  | RETRIEVAL  |\n",
    "|-------------|---------------------------------------------------------------------------|-------------------|------------|\n",
    "| .c          | text/x-c                                                                  |         ✓         |      ✓     |\n",
    "| .cpp        | text/x-c++                                                                |         ✓         |      ✓     |\n",
    "| .csv        | application/csv                                                           |         ✓         |      ✓     |\n",
    "| .docx       | application/vnd.openxmlformats-officedocument.wordprocessingml.document   |         ✓         |      ✓     |\n",
    "| .html       | text/html                                                                 |         ✓         |      ✓     |\n",
    "| .java       | text/x-java                                                               |         ✓         |      ✓     |\n",
    "| .json       | application/json                                                          |         ✓         |      ✓     |\n",
    "| .md         | text/markdown                                                             |         ✓         |      ✓     |\n",
    "| .pdf        | application/pdf                                                           |         ✓         |      ✓     |\n",
    "| .php        | text/x-php                                                                |         ✓         |      ✓     |\n",
    "| .pptx       | application/vnd.openxmlformats-officedocument.presentationml.presentation |         ✓         |      ✓     |\n",
    "| .py         | text/x-python                                                             |         ✓         |      ✓     |\n",
    "| .py         | text/x-script.python                                                      |         ✓         |      ✓     |\n",
    "| .rb         | text/x-ruby                                                               |         ✓         |      ✓     |\n",
    "| .tex        | text/x-tex                                                                |         ✓         |      ✓     |\n",
    "| .txt        | text/plain                                                                |         ✓         |      ✓     |\n",
    "| .css        | text/css                                                                  |         ✓         |            |\n",
    "| .jpeg       | image/jpeg                                                                |         ✓         |            |\n",
    "| .jpg        | image/jpeg                                                                |         ✓         |            |\n",
    "| .js         | text/javascript                                                           |         ✓         |            |\n",
    "| .gif        | image/gif                                                                 |         ✓         |            |\n",
    "| .png        | image/png                                                                 |         ✓         |            |\n",
    "| .tar        | application/x-tar                                                         |         ✓         |            |\n",
    "| .ts         | application/typescript                                                    |         ✓         |            |\n",
    "| .xlsx       | application/vnd.openxmlformats-officedocument.spreadsheetml.sheet         |         ✓         |            |\n",
    "| .xml        | application/xml or \"text/xml\"                                             |         ✓         |            |\n",
    "| .zip        | application/zip                                                           |         ✓         |            |\n",
    "\n",
    "### Retrieval pricing\n",
    "Retrieval is priced at $0.20 per GB per assistant per day. Attaching a single file ID to multiple assistants will incur the per assistant per day charge when the retrieval tool is enabled. For example, if you attach the same 1 GB file to two different Assistants with the retrieval tool enabled (e.g., customer-facing Assistant #1 and internal employee Assistant #2), you’ll be charged twice for this storage fee (2 * $0.20 per day). This fee does not vary with the number of end users and threads retrieving knowledge from a given assistant.\n",
    "\n",
    "In addition, files attached to messages are charged on a per-assistant basis if the messages are part of a run where the retrieval tool is enabled. For example, running an assistant with retrieval enabled on a thread with 10 messages each with 1 unique file (10 total unique files) will incur a per-GB per-day charge on all 10 files (in addition to any files attached to the assistant itself).\n",
    "\n",
    "### Deleting files\n",
    "To remove a file from the assistant, you can detach the file from the assistant. Detaching the file from the assistant removes the file from the retrieval index and means you will no longer be charged for the storage of the indexed file.\n",
    "```python\n",
    "file_deletion_status = client.beta.assistants.files.delete(\n",
    "  assistant_id=assistant.id,\n",
    "  file_id=file.id\n",
    ")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload a file with an \"assistants\" purpose\n",
    "file = client.files.create(\n",
    "  file=open(\"data/Assistants_tools _OpenAI.pdf\", \"rb\"),\n",
    "  purpose='assistants'\n",
    ")\n",
    "\n",
    "# Create an assistant with 'retrieval' enabled and the file is added\n",
    "assistant = client.beta.assistants.create(\n",
    "  instructions=\"You are an assistant who is specialized on 'Tools that can be used with OpenAI Assistants'. You will retrieve the knowledge from the attached file to answer the questions. For the questions that are not related with your specilty, kindly reject to answer.\",\n",
    "  model=\"gpt-4-turbo-preview\",\n",
    "  tools=[{\"type\": \"retrieval\"}],\n",
    "  file_ids=[file.id]\n",
    ")\n",
    "\n",
    "thread = client.beta.threads.create()\n",
    "\n",
    "message = client.beta.threads.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=\"What are the different type of tools that I can use with Assistants API?\"\n",
    ")\n",
    "\n",
    "run = client.beta.threads.runs.create(\n",
    "  thread_id=thread.id,\n",
    "  assistant_id=assistant.id\n",
    ")\n",
    "\n",
    "# Wait for Run to be completed\n",
    "import time\n",
    "\n",
    "while True:\n",
    "    time.sleep(5)\n",
    "    run = client.beta.threads.runs.retrieve(\n",
    "      thread_id=thread.id,\n",
    "      run_id=run.id\n",
    "    )\n",
    "    if run.status in ['queued', 'in_progress', 'requires_action', 'cancelling']:\n",
    "        continue\n",
    "    if run.status in [\"completed\", \"expired\", \"failed\", \"cancelled\"]:\n",
    "        print(f\"Run is {run.status}\")\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask an irrelevant question, see if it rejects. Normally ChatGPT with GPT-4 is responding this question.\n",
    "message = client.beta.threads.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=\"What are the alternative solutions that I can use instead of Redis?\"\n",
    ")\n",
    "\n",
    "run = client.beta.threads.runs.create(\n",
    "  thread_id=thread.id,\n",
    "  assistant_id=assistant.id\n",
    ")\n",
    "\n",
    "# Wait for Run to be completed\n",
    "import time\n",
    "\n",
    "while True:\n",
    "    time.sleep(5)\n",
    "    run = client.beta.threads.runs.retrieve(\n",
    "      thread_id=thread.id,\n",
    "      run_id=run.id\n",
    "    )\n",
    "    if run.status in ['queued', 'in_progress', 'requires_action', 'cancelling']:\n",
    "        continue\n",
    "    if run.status in [\"completed\", \"expired\", \"failed\", \"cancelled\"]:\n",
    "        print(f\"Run is {run.status}\")\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the response\n",
    "messages = client.beta.threads.messages.list(\n",
    "  thread_id=thread.id\n",
    ")\n",
    "\n",
    "for message in reversed(messages.data):\n",
    "  print(f\"_______Role: {message.role}_______\\n\")\n",
    "  # Process annotations before printing the text\n",
    "  import os\n",
    "  text = message.content[0].text.value\n",
    "  annotations = message.content[0].text.annotations\n",
    "  citations = []\n",
    "  for i, annotation in enumerate(annotations):\n",
    "      if (file_citation := getattr(annotation, 'file_citation', None)):\n",
    "          text = text.replace(annotation.text, f'[{i}]')\n",
    "          cited_file = client.files.retrieve(file_citation.file_id)\n",
    "          citations.append(f'[{i}] {file_citation.quote} from {cited_file.filename}')\n",
    "  # Add footnotes to the end of the message before displaying to user\n",
    "  if len(citations) > 0: \n",
    "    text += '\\n' + '\\n'.join(citations)\n",
    "  print(f\"{text}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup\n",
    "assistant_files = client.beta.assistants.files.list(assistant_id=assistant.id)\n",
    "for file in assistant_files:\n",
    "    client.files.delete(file_id=file.id)\n",
    "\n",
    "client.beta.assistants.delete(assistant_id=assistant.id)\n",
    "client.beta.threads.delete(thread_id=thread.id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
